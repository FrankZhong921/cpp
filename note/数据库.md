# SQL基础

## DQL语言



**数据查询语言**

### 子查询

- 子查询（或内查询）：出现在其它语句中的*select* 语句

- 主查询（或外查询）：相对于子查询的外部查询语句

- 分类

  - **按子查询出现的位置：**

    1. **select后面**：仅仅支持标量子查询

    2. **from后面**：支持表子查询

    3. **where 或 having后面**：支持标量子查询、列子查询、行子查询

       - 特点：

         1. **子查询放在小括号内**
         2. 子查询一般放在条件的右侧
         3. 标量子查询一般搭配**单行操作符，>  <   >=  <=  =  <>**
         4. 列子查询一般搭配**多行操作符，in  any/some  all**

       - 标量子查询

         ``` sql
         select * from employees where salary > (select salary from employees where last_name = 'Amen');
         
         select last_name, job_id, salary from employees where salary =(  select min(salary) from employees);
         
         #查询最低工资大于50号部门最低工资的部门id和其最低工资,having子句也可以子查询
         select min(salary), departmend_id from employees group by department_id having min(salary) > (select min(salary) from employees where department_id = 50);

       - 列子查询

       - 行子查询

    4. **exists后面**（相关子查询）：支持表子查询

       - 只关心子查询中是否有值，查询结果是布尔类型，只有1，0

         ```select exist(select department_id from employees)```

         ```sql
         #查询有员工的部门名
         select department_name from departments d where 
         exist(select * from employees e where e.department_id = d.department_ids);
         
         select department_name from departments where
         department_id in (select department_id from employees );
         ```

         

  - **按结果集的行列数不同：**

    1. 标量子查询（结果集只有一行一列）
    2. 列子查询（结果集只有一列多行）
    3. 行子查询（结果集有一行多列）
    4. 表子查询（结果集一般为多行多列）

  

### 分页查询

- 应用场景：

  淘宝商品页，比如搜索男装，可能有10000条数据，但是并不会将整个10000条商品信息在网页中全部显示出来，而是一次只显示一个页面，当我们点击下一页时，向服务器获取另外10条结果。

- 语法：使用 ***limit*** , offset表示起始索引（从零开始），size表示大小

  ```sql
  select 查询列表			 	  7
  from 表						1
  [join type] join 表2			2
  on 连接条件					  3
  group by 分组字段		      4
  having 分组后的筛选			 5
  order by 排序字段			  6
  limit offset,size; 			 8
  #offset = (page -1) * size
  ```

  - tip：对于得到最大值，最小值不一定需要用max, min，也可以通过排序+limit 1获取

### 联合查询

- union ： 将多条查询的语句的结果合并成一个结果，多表的行合并

- 语法：

  ```sql
  查询语句1
  union
  查询语句2
  union
  ...
  ```

- 应用场景：

  一个网站中多个数据库多个数据表，涉及查多个表，且多个表没有连接关系，将多表的查询结果进行合并。 **合并的前提：每个行的列数必须一致。建议(不报错)每一列对应的类型相同**

- **使用union联合查询默认去重，若不需要去重，使用union all**

## DML语言

**数据操作语言：**

### 插入

- 语法１：

  ```sql
  insert into 表名（列名......）
  values (值１...),
  (值２...),
  ...
  ```

  - 注：若插入完整行，则表明后面的列名列表可以省略

  - 若某个列字段允许为空，若表名后面的列名没有省略，则对应值为空必须为NULL，若省略了列名，则对应值可以省略．

    ```sql
    #列名列表省略
    insert into beauty
    values ('柳岩','女','121231414');
    #若性别可为空
    insert into beauty (name,phone)
    values ('柳岩','121231414');
    ```

  - 列名列表的顺序可以调换，但是对应值的位置必须一一对应．

- 语法２：

  ```sql
  #无需列名列表的写法
  insert into 表名
  set 列名＝值，列名＝值;
  ```

- 两种语法的比较

  1. **语法１支持一次插入多行**，语法２不支持

  2. **语法１支持子查询**，语法２不支持

     ```sql
     insert into beauty(id,name,phone)
     select 26,'舒淇'，'1551231515';
     #子查询1
     insert into beauty(id,name,phone)
     select id,boyname,'1241512415'
     from boys where id<3;
     
     #一次插入多行
     insert into beauty(id,name,phone)
     select 26,'舒淇','1551231515'
     union
     select 27,'周迅','1552131415';
     ```

     

### 修改

- 修改单表记录

  - 语法：

    ```sql
    update 表名
    set 列＝值,
    列＝值，
    ...
    where 条件
    ```

    

- 修改多表记录（级联修改）

  - 语法：

    ```sql
    update 表１　别名
    inner|left|right join 表２ 别名
    on 连接条件
    set 列＝值，列＝值,...
    where 筛选条件
    ```

  - ```SQL
    update boys bo
    inner join beauty b on bo.id = b.boyfriend_id
    set b.phone = '114'
    where bo.boyName = 'ASDA';		
    ```

    

### 删除

- 方法１：**delete**

  - 单表删除语法：

    ```sql
    delete from 表名　where 筛选条件;	
    ```

  - 多表删除语法：

    ```sql
    delete 别名1...(别名２)(别名１，别名２)
    from 表１　别名１
    inner | left|right join 表２　别名２
    on 连接条件
    where 筛选条件
    ```

    **注：要删除那个表中对应的记录，取决与delete后面的别名是那个表**

- 方法２：truncate

  - 语法：

    ```sql
    #整个表清空，不能加条件
    truncate table 表名;
    ```

- 方法１vs方法２

  1. delete 可以加where条件，truncate不能加条件;
  2. truncate删除，效率较高
  3. 假如要剔除的表中有自增长列，如果使用delete剔除后，再插入数据，自增长列的值从断点开始，而truncate剔除后，再插入数据．自增长列的值从１开始
  4. truncate删除没有返回值，delete删除有返回值．
  5. truncate删除不能回滚，delete删除可以回滚

## DDL语言

**数据定义语言**

创建：create  修改：alter　删除：drop

### 库的管理

- 创建

  ```sql
  create datebase 库名
  
  #但是如果该库已存在则会出现错误
  create database 库名　if not exists 库名;
  ```

  

- 修改

  ```sql
  #一般不修改库，不安全
  #更改库的字符集
  alter database 库名　character set gbk;
  ```

  

- 删除

  ```sql
  drop database 库名 if exists 库名;
  ```

  

### 表的管理

- 创建

  ```sql
  create table 表名(
  	列名　列的类型 [[长度],[约束]],
  	列名　列的类型 [[长度],[约束]],
  	...
  )
  ```

  

- 修改

  ```Sql
  #修改列名
  alter table 表名　change column 列名　新列名　类型;
  #修改列的类型
  alter  table 表名 modify column 列名　新类型;
  #添加新列
  alter table 表名　add column 新列名　新类型;
  #删除列
  alter table 表名　drop column 列名;
  #修改表名
  alter table 表名　rename to 新表名;
  ```

  

- 删除

  ```sql
  drop table if exists 表名;　#跟drop database 库名 if exists 库名
  show tables;　#显示库中所有表
  ```

- 复制

  ```sql
  #仅仅复制表的结构
  create table 表名 like 参考表名;
  
  #复制表的结构+数据
  create table 表名 select * from author;
  
  #仅仅复制某些结构字段，不要数据(筛选条件不满足即可)
  create table 表名 select 某些字段 from 参考表名　where 0;
  
  ```

  注：跨库查询 from 后面使用　库名.表名 即可．
  
- 查看表的各种属性，如Name,Engine,Row_format,Rows,Avg_row_length,...s

  ```sql
  show table status like '表名'
  ```

  

## 基本数据类型

- 数值型：

  - 整数：Tinyint(8 ) , Smallint(16), Mediumint(24), Int(32), BIgInt(64)

    ```sql
    #整数默认有符号
    #设置无符号
    create table 表名(
    	列名 int unsigned；
    )
    #如果超出表示范围出错　
    #对于整数后面的长度，只表示显示的长度，不表示实际的大小,并且使用zerofill默认无符号
    create table 表名(
    	列名　int(7) zerofill unsigned;
    )
    ```

    整数计算一般使用64位的BIGINT整数，即使在32位环境也是如此。

  - 小数：**Ｍ和Ｄ，Ｄ是小数点后保留Ｄ位，整数位为M-D 位，如果超出范围，则插入临界值9999填补**

    - 浮点型：float(M,D), double(M,D)，根据插入数值决定精度
    
    - 定点型：dec(M,D), decimal(M,D)，默认M=10，D=0，使用D指定小数点后所允许的最大位数。MySQL5.0及高版本将数字打包保存到一个二进制字符串中（每4个字节存9个数字）
    
      MySQL 5.0和更高版本中的DECIMAL类型允许最多65个数字。而早期最高254个数字且保存为未压缩的字符串（每个数字一个字节）
    
    **FLOAT和DOUBLE类型支持使用便准的浮点预算进行近似运算，DECIMAL支持精确计算**，因为需要额外的空间和计算开销，所以应该尽量只在对小数进行精确计算才使用DECIMAL，如存储财务数据，但如果数据量较大时，可以考虑使用BIGINT代替DECIMAL，将小数位数乘积放大到整数即可。

- 字符型：**Ｍ表示最多的字符数，不是最多的字节数**，比如utf-8字符集一个中文字符占3个字节。

  - 较短文本：char \ varchar，char表示固定长度的字符，varchar可变。但char的效率高一点，varchar虽然节省空间，但效率低一些

    - **VARCHAR和CHAR在磁盘和内存中如何存储？**（存储引擎相关）

      - VARCHAR存储变长字符串，可以节省空间，但会使用1~2个字节存储字符串长度(是否超过255个字符)，如果MySQL表使用`ROW_FORMAT=FIXED`创建的话，每行都是**定长存储**。而CHAR类型是定长的，会使用空格填充以方便比较。

      - 由于行是变长的，UPDATE后可能使其比原来更长，空间增长，而页内没有更多空间可以存储，这种情况下不同存储引擎的处理方式是不同的。

        1. MyISAM将行拆成不同的片段存储

        2. InnoDB则需要分裂页来使行可以放在页内

           当字符串列的最大长度比平均长度大很多；列更新很少，所以碎片不是问题，适合使用VARCHAR。CHAR适合存储很短的字符串或者所有值都接近同一个长度，例如MD5值

      - 在5.0或者更高版本，MySQL在存储和检索VARCHAR时会保留末尾空格，但在4.1或更老版本会剔除；当存储CHAR时会剔除所有末尾的空格

      - InnDB可以把过长的VARCHAR存储为BLOB

  

  - 较长文本：text  \ blob（较长的二进制数据）

    - BLOB和TEXT都是为了存储很大数据而设计的字符串类型，分别采用二进制和字符串方式存储

      分别有TINY, SMALL ,   , MEDIUM , LONG；其中BOLB/TEXT是SMALLBLOB/TEXT的同义词。

    - 当BLOB和TEXT值太大时，InnoDB会使用专门的“外部”存储区域来进行存储，此时每个值在行内需要1~4个字节存储一个指针，然后在外部存储区域存储实际值。

    - MySQL对BLOB和TEXT列进行排序与其它类型不同：只对每个列的最前`max_sort_length`字节而不是整个字符串做排序。如果只需要排序前面一小部分字符，可以减小`max_sort_length`的配置。或者使用`ORDER BY SUBSTRING(column,length)`

    - MySQL不能将BLOB和TEXT列全部长度的字符串进行索引，也不能使用这些索引进行排序。

      尽量避免使用这两个类型，不然的话，在所有用到BLOB字段的地方都是用SUBSTRING将列值转换为字符串，这样就可以使用内存临时表，但截取的子字符串需足够短，不会让临时表的大小超过`max_heap_table_size`或`tmp_table_size`，超过以后会将内存临时表转换为MyISAM磁盘临时表

  - 其他：binary,varbinary

    - BINARY和VARBINARY存储的是二进制字符串，与常规字符串非常相似，但是存储的是字节码，并且填充BINARY填充\0而不是空格，在检索时不会去掉填充值。
      - 当需要存储二进制数据，并且希望MySQL使用字节码而不是字符进行比较时非常有用，其优势不仅仅体现在大小写敏感上，每次按一个字节的字节数值进行比较，速度也更快。

  - 其它：enum枚举

    - 枚举列可以把一些不重复的字符串存储成一个预定义的集合。MySQL在存储枚举列时非常紧凑，会根据列表值的数量压缩到一个或两个字节。
    - MySQLz在内部会将每个值在列表中的位置保存为整数，并且在表的.frm文件中保存“数值-字符串”的映射关系
    - **枚举字段是按照内部存储的整数而不是定义的字符串进行排序的**，可以在查询中使用FIELE()函数显式地指定排序顺序，但这会导致MySQL无法利用索引消除排序。
    - 枚举最不好的地方就是，字符串列表是固定的，添加或删除字符串必须使用ALTER TABLE，从而需要重建整个表来完成修改
    - MySQL由于把枚举值保存为整数，并且必须进行查找才能转换为字符串，所以有一定开销。在特定情况下，把CHAR/VARCHAR列与枚举列进行关联可能会比直接关联CHAR/VARCHAR更慢，总的来说，ENUM关联连接ENUM较快，其它不如使用CHAR/VARCHAR。但由于ENUM可以很大程度减少表的占用空间，有关联的开销可能也是值得的。并且如果表上有其它索引，减少主键大小会使非主键索引大小也变得更小。

- 位数据类型：

  - BIT和SET

- 日期型：

  - data(4,日期), datetime(8,日期+时间), timestamp(4，自1970年的秒数), time(3), year(1)

  - date范围(1000 - 9999)，不受时区影响

    timestamp(1970 - 2038)，受时区影响

    ```sql
    #显示时区
    show variables like 'time_zone';
    #修改时区
    set time_zone = '+9:00';
    ```


## 约束

含义：一种限制，用于限制表中的数据，为了保证表中的数据的准确和可靠性，**有列级约束(六大约束都能添加，但外建约束没有效果)和表级约束(写在最后，除了非空，默认，其他都支持)**

```sql
create table 表名(
	字段名　字段类型　列级约束,
	字段名　字段类型,
	表级约束
)
```



1. not null
2. default：默认，用于保证该字段有默认值
3. primary key：主键，保证该字段值唯一且不能为空
4. unique：保证该字段值唯一，但可以为空
5. check：检查约束（mysql不支持，限制字段的取值）
6. foreign key：外键，用于限制两个表的关系，在从表中添加外建约束，用于引用主表中某列的值．保证从表的该字段的值必须来源于主表中存在的g

```sql
create table stuinfo(
	id int primary key,							#主键
	stuname varchar(20) not null,				#非空
	gender char(1) check(gender in ('男','女')), #检查约束
	seat int unique,							#唯一
	age int default 18,							#默认
	majorId int foreign key references major(id)#外键约束
);
```

- **主键vs唯一**：主键不为空，唯一可为空(且null也是唯一)；

  一个表只能有一个主键，唯一可多个；

  主键支持多个字段值组合，唯一也可以支持多字段组合

- **外键**：要求在从表中设置外键关系；

  从表的外键列的类型和主表关联列的类型要求一致或兼容，名称无要求；

  **主表的关联列必须是一个key（一般是主键或唯一）;**

  插入数据时，先插入主表，再插从表；删除数据，先删从表，再删主表

  
  
  

## 标识列

可以不用手动插入值，由系统默认提供.

```sql
show variables like 'auto_increament' #可显示表示列的属性信息
#结果出现
#auto_increment_increment　自增长的步长
#auto_increment_offset		自增长的起始

#修改步长
set auto_increment_increment = 3; 
```

- 创建表时设置标识列

  ```sql
  create table 表名(
  	id int primary key auto_increment,
  	name varchar(20)
  );
  insert into 表名 values(null, 'john');
  ```

- 修改表时设置标识列

  ```sql
  alter table 表名 modify column 列名　int auto_increment;
  ```

- 修改表时删除标识列

  ```sql
  alter table 表名　modify column 列名 int;
  ```



- 特点：

  - 标识符**不一定和primary key搭配，是键(唯一，外键)都行**
  - 一个表只能有１个标识列
  - 标识列的类型只能是**数值型**
  - 可以通过set设置步长，也可手动插入值设置起始

- 标识列类型的选择
  - 整数类型是最好的选择，因为它们很快并且可以使用`auto_increment`
  - ENUM和SET类型：对于某些只包含固定状态或者类型的静态“定义表”来说可能没有问题。但其它时候是个糟糕的选择
  - 字符串类型，尽量避免，因为很消耗空间，尤其是MyISAM中会对字符串默认使用压缩索引，这会导致查询慢得多；对于生成完全“随机”的字符串也需要多加注意，例如MD5()，SHA1()或者UUID()产生的字符串也是，因为它们的分布空间很大，查询时不满足局部性原理。

## 事务

Transaction Control Language 事务控制语言

一个或一组sql语句组成一个执行单元，这个执行单元**要么全部执行，要么全部不执行．**执行失败，整个事务回滚，回到初状态

```show engines```可以显示mysql支持的存储引擎，用的最多的有：innodb, myisam, memory等，其中*innodb* 支持事务，而 *myisam*,*memory* 不支持事务．



### 事务的ACID属性

1. 原子性（Atomicity）:事务是一个不可分割的工作单位，要么发生要么不发生．
2. 一致性（Consistency）：事务必须使数据库从一个一致性状态变换为另一个一致性状态，保证了一致性，即使事务执行过程发生崩溃，所做的修改也不会保存到数据库中，仍是原来的一致性状态。
3. 隔离性（Isolation）：一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰（**很多时候需要隔离级别实现**）
4. 持久性（Durability）：一个事务一旦**提交**，对数据库的改变就是永久性的，接下来的其他操作或数据库故障不应对其有影响．

### 事务的创建

- 隐式事物：事务没有明显的开始和结束的标记，比如insert,update,delete

  ```sql 
  show variables like 'autocommit'; #自动提交　on 开启
  ```

- 显式事务：**必须先设置自动提交功能为禁用**

  ```sql
  set autocommit = 0;	#只针对当前会话有效
  ```

  - 步骤１：开启事务
  - 步骤２：编写事务中的sql语句(select, insert, update, delete)
  - 步骤３：结束事务（commit;提交事物，rollback;回滚）

  ```sql
  # 1	关闭自动提交
  set autocommit = 0;
  start transaction;#这句也可不加
  # 2
  update account set balance 
  # 3
  [rollback] [commit];
  
  ```

  ### 事务的并发问题

  **如果同时运行的多个事务，当这些事务访问数据库中相同的数据时，没有采取隔离机制，就会导致各种并发问题．**

- **脏读**：一个事务Ａ修改数据，但还没有提交，另外一个事务Ｂ读取了修改后的值，若Ａ将事务回滚，则Ｂ出现脏读．

- **不可重复读**：事务Ａ读取了一个字段，之后事务Ｂ对其进行更新并提交，事务Ａ还未提交，此时再读一次结果又不同了．

- **幻读**：一个事务Ａ读取了一个字段，另外一个事务Ｂ插入一些新的行并提交，之后Ａ在事务结束之前又读取了同一个表，此时多出了几行

  更详细的：当前表有id = 1,2,4的记录，事务A使用where id between 1 and 4的查询语句对这个范围内的行上锁，此时另外一个事务B插入id = 3的行后结束，事务A再次查询between 1 and 4中的行发现多了一行。

这些错误，是在事务执行过程中发生的．

### 事务的隔离级别

四种隔离级别

- **Read uncommited(读未提交数据)**

  允许事务读取未被其他事务提交的更新，会出现脏读，不可重复读，幻读

- **Read commited(读已提交数据)**

  **只允许事务读取已经被其他事务提交的变更**，**可以避免脏读**，其他仍会出现

- **Repeatable read(可重复读)**

  确保事务可以**多次**从一个字段中读取相同的值，但这个事务执行过程中禁止其他事务对这个字段进行更新，**可以避免脏读不可重复读**，但仍会出现幻读

- **Serializable(串行化)**

  可以从一个表中读取相同的行，在整个事务持续期间，禁止其他事务对该表执行插入，更新和删除操作．能避免并发问题，但性能很低，阻塞

```sql
#查看默认隔离级别
select @@tx_isolation;
#设置隔离级别(mysql默认repeatable read,oracle 默认read commited)
set session transaction isolation level read uncommitted;
set session transaction isolation level read committed;
set session transaction isolation level repeatable read;
set [session|global] transaction isolation level serializable;


```

**设置保存点**

```sql
set autocommit = 0;
start transaction;
delete from account where id = 25;
savepoint a; #搭配rollback使用,回滚到保存点
delete from account where id = 28;
rollback;
```

### 死锁

死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶行循环的现象。

```sql
start transaction;
update employees set department_id = 1 when id = 4;
update employees set department_id = 2 when id = 3;
commit;


start transaction;
update employees set department_id = 2 where id = 3;
update employees set department_id = 1 where id = 4;
commit;
```

由于使用行级锁，因此事务如果交替进行会出现死锁，因为两个事务分别对id = 3 和 id = 4 的行上锁，两个事务陷入互相等待。



## 存储过程

- 含义：一组预先编译好的SQL语句集合，理解成批处理语句

  1. 提高代码重用性
  2. 简化操作
  3. 减少了编译次数并且减少了和数据库的连接次数，提高了效率

- 创建语法

  ```sql
  #需要先设置结束符，因为若以;作为存储过程的结束符，而存储过程内的语句也以；分隔，则产生歧义  
  #使用$作为结束符，这一句不能以；结束，否则是以　$; 作为结束符
  delimiter $
  create procedure 过程名 (参数列表)
  begin
  	#一组sql操作;
  end$
  
  
  ```

  其中对于参数列表，与函数不同，返回值也是在参数列表中声明，使用参数模式，因此参数列表中每一项由参数模式，参数名和参数类型组成．

  - 参数模式：　in , out , inout

  ```sql
  #举例
  in stuname varchar(20)
  ```

  如果存储过程体仅仅有一句话，*begin* 和 *end* 可以省略，**存储过程体中的每条sql语句**的结尾必须加分号，**存储过程的结尾可以使用*delimiter* 重新设置．** 并且由于设置了delimiter，除非重新设为分号，否则后面的sql语句都需要用$

- 调用语法

  ```sql
  call 存储过程名(实参列表);
  ```

- 删除语法

  ```sql
  drop procedure 存储过程名;#只能删除一个
  ```

- 查看语法

  ```sql
  #不能使用desc
  show create procedure 存储过程名;
  ```

  

- 案例

  - 空参列表

    ```sql
    #插入到admin表中五条记录
    delimiter $
    create procedure myp1()
    begin
    	insert into admin (usrname, password) values
    	('john1','0000'),('lily','1111'),('Tom','2222'),('Toby','4444'),('Tina','5555');
    end $
    call myp1()$
    ```

  - 带in参数模式的列表

    ```sql
    #创建存储过程实现，用户是否登录成功
    create procedure myp2(in username varchar(20), in password varchar(20))
    begin
    	declare result int default 0;	#声明变量
    	select count(*) into result		#判断是否有该用户名和密码对应的条目，若为０则失败
    	from admin
    	where admin.username = username
    	and admin.password = password;
    	select if(result >0 ,'成功','失败');
    end $
    ```

  - 带out参数模式的列表

    ```sql
    #根据女神名，输出她的男朋友及魅力值
    create procedure myp3(in beautyName varchar(20),out boyName varchar(20),out userCP int)
    begin 
    	select bo.boyName, bo.userCP into boyName,userCP	#将数据传入变量！
    	from boys bo
    	inner join beauty b on bo.id = b.boyfriend_id
    	where b.name = beautyName;
    end$
    ```

  - 带inout参数模式的列表

    ```sql
    #传入a,b两个值，最终a和b都翻倍并返回
    create procedure myp8(inout a int, inout b int)
    begin 
    	set a = a*2;
    	set b = b*2;
    end$
    
    #调用
    set @m = 10$
    set @b = 20$
    call myp8(@m,@n)$
    select @m,@n $
    ```

  - ```sql
    create procedure cmpdate (in birth1 datetime, in birth2 datetime, out result int)
    begin
    	select datediff(birth1,birth2) into result;
    end$
    ```

  - ```sql
    #创建一个存储过程，实现传入一个日期，格式化为xx年yy月zz日
    create procedure date_format(in mydate datetime , out str varchar(50))
    begin 
    	select date_format(mydate,'%y年%m月%d日') into str;
    end$
    ```

    **字符转日期　str_to_date    ,   日期转字符　date_format**

  - ```sql
    #传入女神名，返回：'女神　and 男神' 格式的字符串
    create procedure test_pro5(in beautyName varchar(20), out str varchar(50))
    begin
    	select concat(beautyName,'and',ifnull(boyName,'null')) into str
    	from boys bo
    	right join beauty b 
    	on b.boyfriend_id = bo.id
    	where b.name = beautyName
    end$
    ```

## 函数

- 创建语法

  ```sql
  create function 函数名(参数列表) returns 返回类型
  begin
  	函数体
  end
  ```

  注意：参数列表包含两个部分：参数名　参数类型（不再有参数模式）

  ​			**函数体中必有return语句，如果没有则会报错**

  ​			若函数体中只有一句话则可以省略return

  ​			同样使用 *delimiter* 设置结束标记

- 调用语法

  ```sql
  #不是使用call !!! 使用select
  select 函数名(参数列表)
  ```

- 查看函数

  ```sql
  show create function 函数名;
  ```

- 删除语法

  ```sql
  drop function 函数名;
  ```

- 案例

  - 无参有返回

    ```sql
    ＃返回公司的员工人数
    create function myf1() return int
    begin
    	declare c int default 0;
    	select count(*) into c
    	from employees;
    	return c;
    end $
    ```

  - 有参有返回

    ```sql
    #根据员工名，返回它的工资
    create function myf2(empName varchar(20)) returns double
    begin
    	set @sal = 0;
    	select salary into @sal
    	from employees
    	where last_name = empName;
    	return @sal;
    end$
    ```

## 流程控制结构

1. 顺序结构：程序从上到下依次执行
2. 分支结构：程序从两条或多条路径中选择一条去执行
3. 循环结构：程序在满足一定条件的基础上，重复执行的一段代码

### 分支结构

- if函数

  - 功能：实现简单的双分支

  - 语法：

    ```sql
    if(表达式１,表达式２,表达式３)
    #如果表达式１成立，则返回表达式２的值，否则返回表达式３的值
    ```

- case结构

  - 情况１：类型swtich语句，一般用于实现等值判断

    - 语法

      ```sql
      case 变量｜表达式｜字段
      when 要判断的值 then 返回的值１或语句１;
      when 要判断的值 then 返回的值２或语句２;
      ...
      else 要返回的值n或语句n;
      end case;
      ```

      

  - 情况２：类似多重if语句，一般用于实现区间判断

    - 语法

      ```sql
      case 
      when 要判断的条件１ then 返回的值１或语句1;
      when 要判断的条件２ then 返回的值２或语句2;
      ...
      else 要返回的值n或语句n;
      end case;
      ```

  - 特点：

    1. 可以作为表达式，嵌套在其他语句中在使用，可以放在任何地方，begin　end中或外

       可以作为独立的语句去使用，此时只能放在begin end中

    2. 如果when中的值或者条件成立，则执行对应then后面的语句，并且结束case

       如果都不满足则执行else中的语句或值

    3. else可以省略，如果else省略了，并且所有when条件都不满足，则返回null


  - 案例：

    ```sql
    #根据传入的成绩，来显示等级
    create procedure tesr_case(in score int)
    begin
    	case
    	when score >= 90 and score <= 100 then select 'A';
        when score >= 80 then select 'B';
        when score >= 60 then select 'C';
        else select 'D';
        end case
    end$
    ```

- **if 结构**

  - 功能：实现多重分支

  - 语法：

    ```sql
    if 条件１ then 语句１;
    elseif 条件２	then 语句２;
    ...
    else 语句n
    end if;
    ```

  - 特点：应用在　begin 和　end中

  - 案例：

    ```sql
    create procedure test_if(score int) returns char
    begin
    	if score >= 90 and score <= 100 then return 'A';
    	elseif score >= 80 then return 'B';
    	elseif score >= 60 then return 'C';
    	else return 'D';
    	end if;
    end$
    ```

### 循环结构

- 分类：while（先判断后执行）, loop（先执行后判断）, repeat（没有条件的死循环）

- 循环控制：　iterate类似　continue，继续

  ​						leave类似	break，打断

- while

  - 语法：

    ```sql
    [标签：]　while 循环条件 do
    		循环体
    		end while [标签];
    ```

  - 案例

    ```sql
    create procedure pro_while1(in insertCount)
    begin
    	declare i int default 1;
    	a: while i<= insertCount do
    		insert into admin(username,password) values (concat('john',i),'0000');
    		if　i >= 20 then leave a;
    		end if;
    		set i = i + 1;
    	   end while a;
    end $
    ```

    ```sql
    create procedure test_while1(in insertCount int)
    begin
    	declare i int default 0;
    	a: while i <= insertCount do
    		set i = i + 1;
    		if mod(i,2) != 0 then iterate a;
    		end if;
    		insert into admin(username , password) values (concat('john',i),'0000');
    		end while a;
    end$
    call test_while(100)$
    ```

    ```sql
    #产生随机字符串
    delimter $
    create procedure test_randstr_insert(in insertCount int)
    begin
    	declare i int default 1;
    	declare srt varchar(26) default 'abcdefghijklmnopquvwxyz';
    	declare startIndex int default 1;
    	declare len int default 1;
    	while i <= insertCount do
    		set startIndex = floor(rand() * 26 + 1);#rand()产生无限接近１的值
    		set len = floor(rand() * (20 - startIndex + 1) + 1);　#为什么是20而不是26，因为varchar(20)
    		insert into stringcontent(content) values(substr(str,startIndex,len));#在26个字母中随机截取
    		set i = i +1;
    	end while;
    end $
    ```

    

- loop

  - 语法

    ```sql
    [标签：]　loop
    		循环体
    		end loop [标签];
    #可以用来模拟简单的死循环
    ```

- repeat

  - 语法

    ```sql
    [标签：] repeat
    		循环体
    		until 结束循环的条件
    		end repeat [标签];
    ```

    

#  MySql高级

## Linux安装mysql

- 判断是否安装成功

  ```shell
  //需要用户组的相关知识
  cat /etc/passwd | grep mysql
  car /etc/group | grep mysql
  //或者使用--version
  ```

- 设置开机启动

  ```shell
  chkconfig mysql on
  chkconfig --list | grep mysql
  ```
  
  ````shell
  cat /etc/inittab
  #Default runlevel. The runlevels used by RHS are:
  #	0 - halt(Do Not set initdefault to this)
  #	1 - Single user mode	
  #	2 - Multiuser, without NFS(The same as 3)
  #	3 - Full multiuser mode
  #	4 - unused
  #	5 - X11
  #	6 - reboot (Do Not set initdefault to this)
  ````
  
  



## 配置文件

| 路径              | 解释                      | 备注                             |
| ----------------- | ------------------------- | -------------------------------- |
| /var/lib/mysql    | mysql数据库文件的存放路径 | /var/lib/mysql/atguigu/cloud.pid |
| /usr/share/mysql  | 配置文件目录              | mysql.server命令及配置文件       |
| /etc/init.d/mysql | 启停相关脚本              |                                  |

- 修改字符集和数据存储路径

  ```
  //添加下面三行
  character_set_server = utf8
  character_set_client = utf8
  collation-server = utf8_general_ci
  ```

- 主要配置文件

  - 二进制日志log-bin：主从复制
  - 错误日志log-error
  - 查询日志log
  - 数据文件

    - linux下/var/lib
    - frm文件：存放表结构framework
    - myd文件：存放表数据data
    - myi文件：存放表索引index

## mysql架构

链接曾－>业务逻辑层－>存储引擎层－＞存储层

1. 链接层

   最上层是一些客户段和连接服务，包含本地sock通信和大多数基于C/S端工具实现的类型tcp/ip的通信．主要完成一些类似于连接处理，授权认证，及相关的安全方案，在该层上引入了线程池的概念，为通过认证安全介入的客户端提供线程，同样在该层上可以实现基于SSL的安全连接，服务器也会为安全接入的每个客户端验证它所具有的操作权限．

2. 服务层

   第二层架构主要完成大多数的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化及部分内置函数的执行，所有跨存储引擎的功能也是在这一层实现，如函数，过程等．在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等，最后生成相应的执行操作，如果是select语句，服务器还会查询内部的缓存，如果缓存空间足够大，这样在解决大连读操作的环境中能够很好的提高系统的性能．

3. 引擎层

   存储引擎层，存储引擎真正的负责了Ｍysql中数据的存储和提取，服务器通过API与存储引擎进行通信，不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取，如MyISAM和InnoDB

4. 存储层

   数据存储层，主要是见数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互．

   ```sql
   show variables like '%storage_engine%';
   #default_storage_engine		InnoDB
   #storage_engine				InnoDB
   ```

   

   | 对比项   | ＭyISAM                                            | InnoDB                                                       |
   | -------- | -------------------------------------------------- | ------------------------------------------------------------ |
   | 主外键   | 不支持                                             | 支持                                                         |
   | 事务     | 不支持                                             | 支持                                                         |
   | 行表锁   | 表锁，即使操作一条记录也会锁住整个表，不适合高并发 | 行锁，操时只锁某一行，不对其他行有影响，适合高并发           |
   | 缓存     | 只缓存索引，不缓存真实数据                         | 不仅缓存索引还缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响 |
   | 表空间   | 小                                                 | 大                                                           |
   | 关注点   | 性能                                               | 事务                                                         |
   | 默认安装 | Ｙ                                                 | Ｙ                                                           |

   

- 与其他数据库相比，MySql有点与众不同，它的架构可以在多种不同场景中应用并发挥良好的作用，主要体现在存储引擎的架构上．

- **插件式的存储引擎架构将查询处理和其他的系统任务以及数据的存储提取相分离**，这种架构也可以根据业务的需求和实际需要选择合适的存储引擎．

- Percona公司为Ｍysql数据库服务器进行了改进，在功能和性能上较Ｍysql有着显著的提升，提升了高并发下InnoDB的性能，开发了一款存储引擎xtradb可以完全替代InnoDB，被早期的阿里采用，后推出AliSql+AliRedis

- 根据流程图应该知道sql出问题时应该定位在哪一层，sql变慢，索引失效应该定位到业务逻辑层optimizer




## sql执行慢

**执行慢主要由两个时间决定**

- 执行时间长
- 等待时间长

**性能下降可能的原因**

- 查询语句写的烂：创建索引，使用子查询
- 索引失效：用了索引，但是失效，通常是mysql内部优化
- 关联查询太多join(设计缺陷或不得已的需求)
- 服务器调优及各个参数设置(缓冲，线程数等)

### sql Joins

自行脑补画面

- A和B交集

  ```sql
  select * from A inner join B on A.aid = B.nid;
  ```

- A的独有+ＡＢ交集

  ```sql
  select * from A left join B on A.aid = B.bid;
  ```

  由于使用外连接，Ａ独有的，即Ａ.aid没有和Ｂ.bid对应的，因此一行中Ｂ的那部分全部为null

- Ｂ的独有+ＡＢ交集

  ```sql
  select * from A right join B on A.aid = B.bid;
  ```

- A的独有

  ```sql
  select * from A left join B on A.aid = B.bid where B.bid = null;
  ```

- B的独有

  ```sql
  select * from A right join B on A.aid = B.bid where A.aid = null;
  ```

- A和Ｂ并集

  ```sql
  select * from A left join B on A.aid = B.bid
  union
  select * from A right join B on A.aid = B.bid;
  ```

- A和Ｂ并集去除交集（Ａ和Ｂ各自独有的）

  ```sql
  select * from A left join B on A.aid = B.bid where B.bid = null
  union
  select * from A right join B on A.aid = B.bid where A.aid = null;
  ```

  

### SQL解析顺序

from -> join ->on -> where -> group by -> having ->select -> order by -> select -> limit

## 索引

- 什么是索引？

  官方：索引是帮助Mysql高效获取数据的数据结构

  因此，索引是一种数据结构，一种＂**排好序的快速查找数据结构**＂

  - **索引会影响到where后面的查找条件和order by 的排序**

  在数据库之外，还维持这满足特定查找算法的数据结构，这些数据结构以某种方式引用(指向)数据．这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是**索引**．通过会维护**BTree**

- 索引的优势

  1. 提高数据检索的效率，降低数据库的IO成本
  2. 通过索引对数据进行排序，降低数据排序的成本，降低了cpu的消耗

- 索引的劣势

  1. 实际上索引也是一张表，这表保存了主键和索引字段，并指向实体表的记录，所以索引列也是要占用空间的
  2. 虽然索引提高了查询速度，但同时也会降低更新表的速度，如对表进行insert, update和delete时不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段．
  3. 索引只是提高效率的因素之一，如果Mysql有大量数据的表，需要花时间建立最优秀的索引

- 语法

  - 创建

    ```sql
    select * from user where name = 'John';
    #为了select速度更快，创建单值索引
    create index 索引名(通常可以使用idx_表名_字段的格式) on 表名(字段)
    create index idx_user_name on user(name);
    
    #也可创建复合索引
    create index idx_user_name_email on user(name,email);
    
    #alter语法
    alter 表名　add [unique] index 索引名　on 表名(字段);
    ```

  - 删除

    ```sql
    drop index 索引名 on 表名;
    ```

  - 查看

    ```sql
    show index from 表名;
    ```

  - 使用alter命令

    ```sql
    alter table 表名　add primary key(字段名);	　#添加主键约束
    alter table 表名　add unique 索引名(字段名);		#添加唯一索引
    alter table 表名　add index 索引名(字段名);		#添加普通索引
    alter table 表名　add fulltext 索引名(字段名);	#添加全文索引
    ```

- 索引分类：单值索引，唯一索引，复合索引(一个索引包含多个列)



- 那些情况需要创建索引？
  1. 主键自动创建唯一索引
  2. 频繁作为查询条件的字段应该创建索引
  3. 查询中与其他表关联的字段，外键关系创建索引
  4. **频繁更新的字段不适合创建索引**
  5. where条件里用不到的字段不创建索引
  6. 单键/复合索引的选择问题（高并发选择复合）
  7. 查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度
  8. 查询中统计或者分组字段
- 哪些情况下不需要创建索引？

  1. 表的记录太少
  2. 经常增删改的表：因为需要相应修改索引文件
  3. 如果某个字段含有大量重复值则无需创建
     - 索引的选择性是指索引列中不同值的数目与表中记录个数的比

## 性能分析

1. MySql Query Optimizer
2. MySql常见瓶颈
3. Explain



- MySql Query Optimizer																			

  1. MySql中有专门负责优化select语句的优化器模块，主要功能：通过分析计算系统中收集到的统计信息，为客户端请求的Query提供**它认为最优**的执行计划．
  2. 客户端向MySql请求一条Query，命令解析器模块完成请求分类，区别出是select并转发给MySql Query Optimizer时，MySql Query Optimizer首先会对整条Query进行优化，处理掉一些常量表达式的运算．直接换算成常量值，并对Query中的查询条件进行简化和转换，如去掉一些无用或显而易见的条件，结构调整等，然后分析Query中Hint信息（如果有）,看显示Hint信息是否可以完全确定该Query的执行计划，如果没有Hint或Hint信息还不足以完全确定执行计划，则会读取所涉及对象的统计信息，根据Query进行写相应的分析计算，然后再得出最后的执行计划．

- MySql常见瓶颈

  1. CPU：在CPU饱和的时候发生在数据装入内存或从磁盘上读取数据时
  2. IO：磁盘I/O瓶颈发生在装入数据远大于内存容量的时候
  3. 服务器硬件的性能瓶颈：top,free,iostat和vmstat来查看系统的性能状态

- Explain

  - 是什么

    | id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows | extra |
    | ---- | ----------- | ----- | ---- | ------------- | ---- | ------- | ---- | ---- | ----- |

  - 能干嘛

    - 表的读取顺序：id
    - 数据读取的操作类型：type
    - 哪些索引可以使用：possible_keys
    - 哪些索引被实际使用：keys
    - 表之间的引用：ref
    - 每张表有多少行被优化器查询：rows

  - 怎么用

  - 各字段解释

    - id：如果是子查询id会递增，**id越大的优先级越高**，越先执行；**同id值，按从上到下的顺序依次执行**

    - select_type：主要用于区别是普通查询，联合查询，子查询等

      | i    | select_type                                                  |
      | ---- | ------------------------------------------------------------ |
      | 1    | SIMPLE，简单的查询，不包含子查询或者UNION                    |
      | 2    | PRIMARY，查询中若包含任何复杂的子部分，最外层查询则被标记PRIMARY |
      | 3    | SUBQUERY，在select或where列表中包含了子查询                  |
      | 4    | DERIVED，在from后面的子查询，mysql会递归执行这些子查询并把结果存入临时表 |
      | 5    | UNION，若第二个select出现在union之后则标为UNION，若union在from后的子查询中，外层select标为DERIVED |
      | 6    | UNION RESULT，从UNION表获取结果的select                      |

      

    - table：查询用的是哪张表，**其中 *derived* 表示衍生表，其后面的数字是id字段的值**

    - type：显示查询使用了何种类型

      - 从最好到最差依次是（仅列举常见类型）：

        **system > const > eq_ref > ref > range > index > all**

      - | system | 表只有一行记录(等于系统表)，这是const类型的特例，不常见      |
        | ------ | ------------------------------------------------------------ |
        | const  | 表示**通过索引一次就找到**了,const用于比较primary key或unique，如将主键置于where列表这种，mysql就能将该查询转换为一个常量． |
        | eq_ref | 唯一性索引扫描，对于每个索引键，表中都只有一条记录与其对应   |
        | ref    | 非唯一性索引扫描，对于一个索引键有多条记录                   |
        | range  | 只检索给定范围的行，一般就是在where语句后出现between, <, >, in等 |
        | index  | Full Index Scan，Index与ALL区别为index类型只遍历索引树       |
        | all    | Full Table Scan，全表扫描                                    |

        **一般来说，要保证查询至少到达range级别，最好能到ref．**

    - possible_keys和key：可能会出现的索引和结果一定出现的索引

    - key_len：表示索引最大可能使用的字节数，根据定义计算得到的，不丢失精度下越小越好

    - ref：显示索引的哪一列被使用了，如果可能的话，是一个常数．哪些列或常量被用于查找索引列上的值

    - rows：找到匹配结果可能需要查找的行数

    - extra：额外信息

      - | using filesort               | 说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取．ＭySql中无法利用索引完成的排序操作称为"文件排序" |
        | ---------------------------- | ------------------------------------------------------------ |
        | using temporary              | 使用了临时表保存中间结果，ＭySql在对查询结果排序时使用临时表．常见于排序order by和分组查询group by |
        | using index                  | 如果同时出现using where，表明索引被用来执行索引键值的查找    |
        | using where                  | 如果没有同时出现using where，表明索引用来读取数据而非执行查找动作 |
        | using join buffer            | 使用了连接缓存，此时可适当增加缓存大小                       |
        | impossible where             | where总是false，例如where name ='a' and name = 'c'，不可能同时满足 |
        | select tables optimized away | 在没有group by 子句的情况下，基于索引优化MAX/MIN操作或者对于MyISAM存储引擎优化count(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化． |
        | distinct                     | 优化distinct操作，在找到第一个匹配的元组后即停止找同样值的动作． |

        

  - 热身case

## 索引失效

1. 全值匹配

2. 最佳左前缀法则

   - 如果索引了多列，要遵守最左前缀法则，指的是查询从索引的最左列开始并且不跳过中间列

   - ```sql
     create index idx_staffs_nae on staffs(name,age,email);
     #全值匹配
     explain select name,age,email from staffs where name = 'abc' and age = 16 and email = '123@163.com';
     #部分匹配
     explain select name,age,email from staffs where name = 'abc' and email = '123@163.com';
     #没能用到索引
     explain select name,age,email from staffs where age = 16 and email = '123@163.com';
     ```

3. 不在索引列上做任何操作（计算，函数（自动or手动）类型转换），会导致索引失效而转向全表扫描

   - 

4. 存储引擎不能使用索引中范围条件右边的列

   - ```sql
     #部分索引，只用到name,age，由于age是范围，所以其右边的的email索引失效
     explain select name,age,email from staffs where name ='abc' and age >16 and email ='123@163.com';
     ```

5. 尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少select*

   - ```sql
     #使用select* ,出现using where
     explain select * from staffs where name = 'abc' and age = 16 and email = '123@163.com';
     #使用select name,age,email，出现using where,using index
     explain select name,age,email from staffs where name = 'abc' and age = 16 and email = '123@163.com';
     #虽然都有运用索引，但using where 和using index同时出现效率更高
     ```

6. mysql在使用不等于(!= 或者<>)的时候无法使用索引会导致全表扫描

7. is null, is not null也无法使用索引

8. like以通配符开头('%abc...')，索引失效会变成全表扫描的操作

   - ```sql
     explain select * from staffs where name like '%John'; #索引失效,type = all
     explain select * from staffs where name like 'John%'; #索引成功，type = range
     explain select * from staffs where name like '%John%';#索引失效，type = all
     explain select name,age,email from staffs where name like '%John'; #索引成功，type = range
     explain select name,age,email,department from staffs where name like '%John'; #索引失败，字段多于索引字段
     ```

9. 字符串不加单引号索引失效

   - ```sql
     explain select * from staffs where name = '2000';	#索引成功
     explain select * from staffs where name = 2000;		#索引失效
     ```

10. 少用or，用它来连接时索引会失效

- 案例

```sql
explain select * from test where c1 ='a1' and c2 = 'a2' and c3 >'a3' and c4 = 'a4';
#type = range, key = idx_test_c1234 key_len = 93 
explain select * from test where c1 ='a1' and c2 = 'a2' and c4 >'c4' and c3 = 'a3';
#type = range, key = idx_test_c1234 key_len = 124
#在第二种情况下，从key_len可以看出用到了４个索引，原因在于数据库的优化器将c4和c3调换顺序
```



```sql
explain select * from test where c1 ='a1' and c2 = 'a2' and c4 = 'a4' order by c3;
#type = ref, key = idx_test_c1234, key_len = 62，using where

explain select * from test where c1 ='a1' and c2 = 'a2' order by c3;
#type = ref, key = idx_test_c1234, key_len = 62, using where
#在第一和第二种情况相同，只用到两个索引用于查找，由于c1,c2都是const，因此也用到c3进行排序
```

```sql
explain select * from test where c1 ='a1' and c2 = 'a2'  order by c4;
#type = ref, key = idx_test_c1234, key_len = 62, using filesort
#排序字段没有按照最左前缀匹配原则，使用了文件索引
```

```sql
explain select * from test where c1 ='a1' and c5 = 'a5' order by c2,c3;
#type = ref, key = idx_test_c1234, key_len = 31, using where
#用到一个索引进行查找，由于第一个字段索引为const，所以c2,c3两个字段索引用来排序

explain select * from test where c1 ='a1' and c5 = 'a5' order by c3,c2;
#type = ref, key = idx_test_c1234, key_len = 62, using filesort

explain select * from test where c1 ='a1' and c2 = 'a2' and c5 = 'a5' order by c3,c2;
#type = ref, key = idx_test_c1234, key_len = 62, using where

#第二，三种情况的区别在于　先执行where再执行order by，其中c2查出来是const,因此在order by后面只有一个记录，相当与无效
```



```sql
explain select * from test where c1 ='a1' and c4 = 'a４' group by c3,c2;
#type = ref, key = idx_test_c1234, key_len = 31, using filesort
#group by需要使用先排序再分组，会有临时表产生，因此group by不符合最左前缀匹配，使用了文件排序
```



### 一般性建议

- 对于单键索引，尽量选择针对当前query过滤性更好（越经常使用）的索引
- 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好
- 在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引
- 尽可能通过分析统计信息和调整query的写法来选择合适索引的目的

## 查询截取分析

- 步骤：
  - 慢查询的开启与捕获
  - explain + 慢sql分析
  - show profile查询sql在MySql服务器里面的执行细节和生命周期情况
  - sql数据库服务器的参数调优

### 查询优化

- 优化原则：**小表驱动大表，即小的数据集驱动大的数据集**

- ```sql
  select * from A where id in (select id from B)
  #等价于
  for select id from B
  for select * from A where A.id = B.id
  
  #当Ｂ表数据集必须小于Ａ表的数据集时，用in优于exists.
  ```

- ```sql
  select * from A where exists (select 1 from B where B.id = A.id)
  #等价于
  for select * from A
  for select * from B where B.id = A.id
  
  #当Ａ表的数据集小于Ｂ表的数据集时，用exists优于in．
  ```

- select ... from table exists (subquery) 可以理解为：**将主查询的数据，放到子查询中做条件验证，根据验证结果(true 或 false)来决定主查询的数据结果是否得以保留．**

  - 注：exists (subquery) 只返回true或false，因此subquery中的select * 可以换成select 1或　select 'a'或其他．官方说法是实际执行时会忽略select清单，因此没有区别．



- **order by子句，尽量使用index方式排序，避免出现using filesort**

  - mysql支持两种方法进行排序：Index和filesort，其中index排序直接扫描索引本身完成排序
    - order by满足两种情况下会使用index方式排序
      1. order by语句使用索引最左前缀
      2. 使用where子句与order by子句条件列组合满足索引最左前缀

- **尽可能在索引列上完成排序操作，遵守索引键的最佳左前缀**

- **如果不在索引列上，filesort有两种算法进行排序**

  - **双路排序**：MySql4.1之前是使用双路排序，即两次扫描磁盘，最终得到数据

    读取行指针和order by列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据

  - **单路排序**：从磁盘读取查询需要的所有列，按照order by列在buffer中对他们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据．并且把随机I/O变成了顺序I/O，但是它会使用更多的空间，因为每行都在内存中

  - 注意：

    - 在sort_buffer中，单路比双路要占更多空间，因为单路将所有查询字段取出，所以可能取的数据总大小超出sort_buffer容量，导致每次只取sort_buffer容量大小的数据，进行排序（创建tmp文件，多路合并），排完再继续取出来排序，导致多次I/O．

- **优化策略**

  - **增大sort_buffer_size参数的设置**，不管使用单路还是双路排序，增大该参数都能提高性能

  - **增大max_length_for_sort_data参数的配置**，增大该参数可以提高使用单路排序的概率

  - why?

    为了提高order by的速度

    - order by时使用select * 是大忌，应该仅查询需要的字段
      1. 当查询的字段大小总和小于max_length_for_sort_data而且排序字段不是text|blob类型时，才会使用单路排序
      2. 提高sort_buffer_size防止一旦数据量过大而又使用单路排序反而执行更多次IO操作

- **小总结**

### 慢查询日志

​	

### 批量数据脚本

### Show Profile

### 全局查询日志

# 高性能MySQL

## MySQL服务器逻辑架构

![image-20210606172756029](C:\Users\921-\AppData\Roaming\Typora\typora-user-images\image-20210606172756029.png)

- **最上层**，大多数基于网络的客户端/服务器架构工具或者服务都有类似的架构。比如连接处理，授权认证、安全等
- **第二层架构**，大多数MySQL的核心服务功能都在这一层，包括查询解析、分析、优化、缓存以及所有的内置函数（日期、时间、数学和加密函数），所有跨存储引擎的功能都在该层实现：存储过程、触发器、视图等。
- **第三层**包含了存储引擎。存储引擎负责MySQL中数据的存储和提取。每个存储引擎都有它的优劣。通过API屏蔽存储引擎的细节差异，API包含几十哥底层函数，用于执行诸如“开启一个事务”或者“根据主键提取一行记录”等操作。但**存储引擎不会解析SQL**，不同存储引擎之间也不会相互通信，而**只是简单地相应上层服务器的请求**。

## 优化与执行

MySQL会解析查询，并创建内部数据结构（解析树），然后对其进行各种优化，包括重写查询、决定表的读取顺序、以及选择合适的索引等。

- 用户可以通过关键字(***hint***)提示优化器，影响他的决策过程
- 也可以请求优化器解释(***explain***)优化过程的各个因素，使用户可以指导服务器使如何进行优化决策的。并提供一个参考便于用户重构查询

### 死锁问题

- **死锁的产生有双重原因**：

1. 因为数据冲突
2. 完全是由于存储引擎的实现方式导致的。以同样的顺序执行语句，有点存储引擎会产生死锁，有些则不会。

- **解除死锁的方法**

  死锁发生以后，只有部分或者完全回滚其中一个事务，才能打破死锁。对于事务型的系统，这是无法避免的。

  - 数据库系统实现了各种死锁检测和死锁超时机制。越复杂的系统，比如InnoDB引擎，就越能检测到死锁的循环依赖，并立即返回一个错误。**目前InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。**
  - 还有一种解决办法就是等待超时时间，放弃锁请求。

### 事务日志

事务日志可以帮助提高事务的效率。

使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久再硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。

事务日志采用追加的方式，写日志操作的时磁盘上一块区域的顺序I/O而不是随机访问时需要在磁盘的多个地方移动磁头。

事务日志持久后之后，内存中被修改的数据可以在后台慢慢地刷回磁盘。目前大多数存储引擎都是这样实现的，称为预写式日志(Write-Ahead-Logging)，修改数据需要写两次磁盘。

如果数据的修改记录到事务日志并持久化，而数据还没写回磁盘就崩溃，存储引擎在重启时能够自动恢复这部分数据。

## MySQL中的事务

**MySQL提供了两种事务型的存储引擎：InnoDB和NDB Cluster.**另外还有一些第三方的存储引擎也支持事务，比较知名的包括**XtraDB**和PBXT.

### 自动提交

```sql
show variables like 'autocommit';
```

当autocommit=0时，所有的查询都是在一个事务中，直到显式地执行commit或rollback回滚，该事务？结束，同时又开始了另外一个新事务（这个新事务的autocommit是开还是关？）

**修改autocommit对非事务型的表，比如MyISAM或者内存表，不会又任何影响。对它们来说，没有commit或者rollback的概念，相当于一直是autocommit = on 的状态。**

在DDL中，如果是会导致大量数据改变的操作，如`ALTER TABLE`，在执行之前会强制执行commit提交当前的活动事务。还有`lock tables`等其它语句也会导致同样的结果。（**可检查对应mysql版本的官方文档来确认**）

### 设置隔离级别

MySQL可以通过`set transaction isolation level` 命令来设置隔离级别。新的隔离级别会在下一个事务开始的时候生效

### 在事务中混合使用存储引擎

MySQL服务层不管理事务，事务是由下层的存储引擎实现的。所以在同一个事务中使用多种存储引擎是不可靠的。

- 如果事务中使用了事务型和非事务型的表，在需要回滚时，非事务表的变更无法撤销。

### 隐式和显示锁定

InnoDB采用的是两阶段锁定协议(two-phase locking protocol). 在事务执行过程中，随时可以执行锁定（根据隔离级别，对查询的行或者表上锁）。只有在`commit`或`rollback`的时候才会释放，这是**隐式锁定**。

显示锁定不属于SQL规范

- `SELECT ... LOCK IN SHARE MODE`
- `SELECT ... FOR UPDATE`

MySQL也支持`LOCK TABLES`和`UNLOCK TABLES`，这是**在服务层实现**的，和存储引擎无关（事务是在存储引擎实现的），它们有自己的用途，不能代替事务处理。**如果需要事务，应该使用事务型存储引擎**。

### 多版本并发控制(MVCC)

可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。

- MVCC的实现，是通过保存数据在某个时间点的快照来实现的。也就是说，不管需要执行多长时间，每个事务看到的数据都是一致的。

- 根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。

  

**InnoDB**的MVCC，是通过在每行数据后面保存两个隐藏列来实现的

1. **保存了行的创建时间**
2. **保存了行的过期时间**

- 所谓时间其实是**系统版本号**(system version number)。每开始一个新的事务，系统版本号都会自动递增。
- **事务开始时刻的系统版本号**，会作为事务的版本号，用来和查询到的每行的版本号比较
  - SELECT
    - **只查找版本早于（小于）当前事务版本的数据行**，确保事务读取的行，要么在事务开始前已经存在，要么是事务自身插入或者修改过。（如果在查找范围，而又查找行的版本大于当前事务版本就不显示吗？？？看UPDATE）
    - **行的删除版本要么未定义，要么大于当前事务版本号**，确保事务读取到的行在事务开始前已经被删除
  - INSERT\DELETE
    - 初始化对应的版本号
  - UPDATE
    - 插入一行新记录，**保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。**（新旧行记录都在，那么SELECT如何保证是最新的）
- 使用该MVCC的不足之处在于每行记录都需要额外的存储空间，需要做更多的行检查工作，以及额外的维护工作。

不同存储引擎的MVCC实现不同，典型的有：

1. **乐观(optimistic)并发控制**
2. **悲观(pessimistic)并发控制**

- **MVCC只在REPETABLE READ  和 READ COMMITED两个隔离级别工作**，其它两个隔离级别都和MVCC不兼容
  - 因为READ UNCOMMITED总是读最新的数据行，而不是当前事务版本的行
  - SERIALIZABLE则对所有读取的行都加锁，即相当于所有的行的并发版本相同。每改动一行需要同步所有行

## InnoDB存储引擎（5.1后默认）

在MySQL4.1以后的版本中，**InnoDB可以将每个表的数据和索引存放在单独的文件中**，也可以使用裸设备作为表空间的存储介质，但现在的文件系统使得裸设备不再是必要选择。

- 裸设备(raw device)，也叫裸分区（原始分区），是一种**没有经过格式化，不被Unix通过文件系统来读取的特殊块设备文件**。由应用程序负责对它进行读写操作。**不经过文件系统的缓冲**。它是不被操作系统直接管理的设备。这种设备少了操作系统这一层，I/O效率更高。不少数据库都能通过使用裸设备作为存储介质来提高I/O效率。



**InnoDB采用MVCC来支持高并发**，并且实现了四个标准的隔离级别。默认级别是可重复读(REPEATABLE READ)，并且通过间隙锁(next-key locking)策略防止幻读的出现。

- 间隙锁：对索引中的间隙进行锁定，以防止幻影行的插入



**InnoDB表是基于聚簇索引建立的**。InnoDB的索引结构和MySQL的其它存储引擎有很大的不同，聚簇索引对主键查询有很高的性能，不过它的二级索引（secondary index,非主键索引）中必须包含主键列，所以主键列很大的化，其它的所有索引都会很大。InnoDB的存储格式是平台独立的，也就是苏红可以将数据和索引文件从Intel平台复制到PowerPC平台或是Sun SPARC平台。

## MyISAM存储引擎

MyISAM提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等，但MyISAM不支持事务和行级锁，更重要的食崩溃后无法安全恢复。

**MyISAM会将表存储在两个文件中：数据文件和索引文件**，分别以.MYD和.MYI为扩展名。

在MySQL 5.0中，MyISAM表如果是变长行，则默认配置只能处理256TB的数据，因为**指向数据记录的指针长度是6个字节**。而在更早的版本中，指针长度默认是4字节，所以只能处理4GB的数据。而**所有版本的MySQL都支持8字节的指针**，要改变MyISAM表指针的长度，可以通过修改表的*MAX_ROWS*和*AVG_ROW_LENGTH* 选项的值来实现，两者相乘就是表可能达到的最大大小。但会修改会导致索引重建，需要很长时间。

**MyISAM对表加锁，读取时加共享锁，写入时加排他锁。但是在表有读取查询的同时，也可以往表中插入新的记录。（这称为并发插入，CONCURRENT INSERT）**

**创建MyISAM表的时候，如果指定了DELAY_KEY_WRITE选项，在每次修改执行完成时不会立即将修改的索引数据写入磁盘，**而是会写到内存中的键缓冲区(in-memory key buffer)，只有在清理缓冲区或者关闭表才会将对应的索引块写入到磁盘。**虽然提高写入性能，但在数据库或主机崩溃时会造成索引损坏。**



如果表在创建表导入数据以后不再进行修改操作，那么这样的表或许适合采用MyISAM压缩表。

**可以使用myisampack对表进行压缩。**但是压缩表修改必须先解压，修改，再压缩。压缩表可以极大减少磁盘占用，其中索引也是只读的。

对大多数应用场景，读取压缩表数据时的解压带来的开销影响并不大，而减少I/O带来的好处更多。**压缩表中的记录是独立压缩的，所以读取单行的时候不需要去解压整个表。**

## 转换表的引擎

1. *alter table*

   `ALTER TABLE mytable ENGINE = InnoDB;`

   该语法可以适用任何引擎，但执行需要很长的时间。先把数据复制到新表，同时原表上会加入读锁。一种替代方案是导入导出

2. 导入导出

   使用mysqldump工具将数据导出到文件，然后修改文件中create table语句的存储引擎选项。同时注意mysqldump默认会自动再create table语句前面加上drop table语句，不注意这一定可能导致数据丢失。

3. 创建与查询(CREATE 和 SELECT)

   结合了第一种方法的高效和第二种方法的安全。

   ```sql
   create table innodb_table like myisam_table;
   alter table innodb_table engine = InnoDB;
   insert into innodb_table select * from myisam_table'
   ```

   数据量不大的话还行，数据量很大时，可以考虑做分批处理

   ```sql
   start transaction;
   insert into innodb_table select * from myisam_table where id between x and y;
   commit;
   ```



## 基准测试

- 为什么要基准测试？

  - 验证系统的某一些假设
  - 重现系统中的某些异常
  - 测试系统当前的运行情况
  - 模拟高负载从而找出系统的瓶颈

- 测试策略：

  - 集成式(*full-stack*)测试
    - 不仅仅关心MySQL本身的性能，而是应用整体的性能
    - MySQL并非总是应用的瓶颈
  - 单组件测试(*single-component*)测试
    - 避免漫长的集成式测试

- **测试指标：**

  1. **吞吐量(throughput)**

     单位时间内的事务处理数。常用测试单位：TPS，TPM

  2. **延迟(latency)或响应时间**

     测试从请求到接收到响应的时间。可求出平均响应时间，最小响应时间和最大响应时间，**但是最大响应时间通常随着测试时间而不断增大，没有代表性。**通常使用百分比响应时间(percentile response time)来替代最大响应时间。

  3. 并发性

     通常被有多少个同时**工作的**线程数或者连接数。创建数据库连接和并发性不同，因为可能只有少数连接在执行查询。并发性关注的是：当并发性增加时，吞吐量是否下降，响应时间是否变长，如果是这样，应用可能就无法处理峰值压力。

  4. 可扩展性

     理想情况下，给系统增加一倍的性能，吞吐量也能增加一倍，当然响应时间也在可接受范围内。但大多数系统无法做到。

- **测试的基本方法**

  - 可能导致错误的测试结果
    1. 使用错误的数据分布，真实数据通常由热点数据，而不应该使用均匀分布的数据测试
    2. 在多用户场景中做单用户的测试
    3. 反复执行某一个查询，使得数据缓存命中率增加
    4. 忽略系统预热(warm up)的过程，系统刚启动时缓存时冷的
    5. 基准测试完检查错误日志是最基本的要求
  - 

  

## 服务器性能剖析

最常碰到的三个性能相关的服务请求时：

1. 如何确认服务器是否达到了性能最佳状态
2. 找出某条语句为什么执行不够快
3. 诊断被用户描述成“停顿“、”堆积“或者卡死”的某些间歇性疑难故障

看起来任务比较艰巨，一个简单的方法就是专注于测量服务器的时间花费在哪里，使用的技术则时性能剖析( ***profiling***) 。

性能根据不同的场景不同，侧重点不同，例如：“每秒查询次数”、“CPU利用率”、“可扩展性”之类，我们则专注于完成某件事情所需要的时间，性能即响应时间。

- 要理解服务器执行查询为什么这么多时间，就必须先知道时间花在什么地方，因此不是一上来就把精力放在修改一些东西上，而不去做精确的测量。**通过精确的测量，分析得知响应时间花在哪里，再对症下药。**

- 两种比较常见的导致不精确测量的情况

  1. 在错误的时间启动和停止测量
  2. 测量的是聚合后的信息，而不是目标活动本身

  - 例如，一个常见的错误是先查看慢查询，然后又去排查整个服务器的情况来判断问题再哪里。如果确认又慢查询，那么就应该测量慢查询，而不是测量整个服务器。测量的应该是从慢查询的开始到结束的时间，而不是查询之前或之后。

**完成一项任务所需要的时间：执行时间和等待时间**

### 通过性能剖析进行优化

性能剖析是测量和分析时间花费再哪里的主要方法。性能剖析一般有两个步骤：测量任务所花费的时间，然后对结果进行统计和排序，将重要的任务排再前面。

性能剖析报告会列出所有任务列表。每行记录一个任务，包括任务名、任务的执行时间......，其中有些没有显示出来的信息也很重要，部分执行时间长，但是频率低的查询总的响应时间占比并不突出，通过偏差等依赖于剖析工具才能观察到。

### 剖析MySQL查询

#### 捕获MySQL的查询到日志文件中

在MySQL5.0及之前的版本中，慢查询日志的响应时间的单位是秒，粒度太粗，而5.1之后，可以通过设置`long_query_time`为0来捕获所有的查询，并且粒度达到了微妙级。*Percona Server的慢查询记录了更多细节。*

如果长期开启慢查询日志，主要要部署日志轮转(*log rotation*)工具。或者不要长期启用慢查询日志，只在需要手机负载样本的期间开启即可。

还有一种查询日志被称为“通用日志”，但很少用于分析和剖析服务器性能。通用日志在查询请求到服务器时进行记录，所以不包含响应时间和执行计划等重要信息。

此外还可以通过tcpdump抓包并保存到磁盘，然后通过MySQL的客服端、服务端通信协议进行解析，该方法精度比较高。

#### 分析查询日志

不要直接打开整个慢查询日志进行分析，这样做之后浪费时间精力。首先应该生成一个剖析报告，如果需要，则可以再查看日志中需要特别关注的部分。

- 一款从慢查询日志中生成剖析报告的工具，`pt-query-digest`，支持将报告保存到数据库中，以及追踪工作负载随时间的变化。

  ![image-20210609161028571](E:\cpp\note\note_picture\image-20210609161028571.png)

#### 剖析单条查询

确认为什么会花费这么长的时间执行，以及需要如何去优化。**主要是使用工具方便地测量查询执行的各部分花费了多长时间**

- **使用 SHOW PROFILE**

  **默认是禁用的**，但可以通过服务器变量在会话级别动态地修改

  `SET profiling = 1;`

  然后，在服务器上执行的所有语句，都会测量其耗费的时间和其它一些查询执行状态变更相关的数据。当一条查询提交给服务器时，此工具会记录剖析信息到一张临时表，并且给查询赋予从1开始的标识符，并且表中数据按执行顺序排序，我们可以使用查询语句查看该表使其按响应时间排序。

  ```sql
  show profiles; #显示该会话下执行的所有SQL，以及Query_ID,Duration时间
  ```

  ```sql
  show profile for query 1; #显示Query_ID = 1的SQL语句执行了什么操作以及每个操作花费的时间
  ```

  为了查看哪个操作花费的时间最长，我们不使用`show profile`命令，而是直接查询`INFORMATION_SCHEMA`中的表并格式化输出。

  ```sql
  select state, sum(duration) as total_r, round( 100 * sum(duration) / (select sum(duration) from information_schema.profiling where query_id = @query_id),2) as pct_r, count(*) as calls,
  sum(duration) / count(*) as "r/call"
  from information_schema.profiling
  where  query_id = @query_id
  group by state
  order by total_r desc;
  ```

  自此，剖析报告帮助我们定位到哪些活动花费了这么多时间。但是没有告诉我们为什么会这样。比如是什么造成了Copying to tmp table花费最长的时间。

- **使用 SHOW STATUS**

  **MySQL的SHOW STATUS命令返回了一些计数器，有全局也有会话级别的计数器**，其中会话级别开始时为0，每提交一条查询增加1。**该工具可以显示某些活动如读取索引的频繁程度，但无法给出消耗了多长时间。**最有用的计数器包括句柄计数器、临时文件和表计数器等。

  ```sql
  flush status;		#清空计数器
  show status where Variable_name like 'Handler%' or Variable_name like 'Created%';
  ```

  使用该技术时本身也会创建一个临时表，我们使用查询语句访问该表也会增加其计数。

  

  使用***EXPLAIN*** 也可以获得大部分相同的信息，但它是通过估计而不是实际测量，***EXPLAIN*** 也无法告知临时表是否是磁盘表，这和内存临时表的性能差别也很大。

- **使用慢查询日志**

  Percona Server对慢查询日志做了改进，包含了`show profile`和`show status`的所有条目。通过`pt-query-digest`发现“坏”查询之后，在慢查询日志中可以获得足够有用的信息。

  - 查看`pt-query-digest`后其标题部分一般会有以下输出：

    `#Query 1: 0 QPS ,0x concurrency, ID 0xEE98YYAC98A8931 at byte 3214`

    其中 3214 是字节偏移值，通过 `tail -c +3214 /path/to/query.log | head -n100`可以直接跳转到该日志查询语句的位置

- **使用Performance Schema**

### 单条查询问题还是服务器问题

如果服务器上所有的程序都突然变慢，又突然都变好，每一条查询也都变慢了，那么慢查询可能就不是原因。

服务器的问题非常常见。过去几年，硬件的能力越来越强，配置16核或者更多CPU的服务器成了标配，MySQL在***SMP架构***的机器上可扩展性限制也越来越显露出来。

- **SMP架构（Symmetric Multi-Processor，对称多处理器结构）**
  - 该架构下所有CPU共享全部资源，如总线、内存等，多个CPU之间没有区别，平等的访问内存，因此SMP也被称为一致存储器访问结构(UMA: Uniform Memory Access)。如果两个CPU同时请求同一个资源，由硬件、软件的锁机制取解决资源争用问题，因此其扩展能力非常有限，随着CPU数量的增加，内存访问冲突将迅速增加，最终造成CPU资源浪费。
- **NUMA架构（Non-Uniform Memory Access，非一致性存储访问结构）**
  - 为了减少SMP在扩展能力上的限制，利用NUMP技术可以把几十个CPU组合在一个服务器内。NUMP服务器的基本特征是有多个CPU魔窟啊，每个模块有多个CPU，并且具有独立的本地内存、I/O槽口等。每个模块可以通过互联模块(Crossbar Switch)进行连接和信息交互，因此每个CPU可以访问整个系统的内存。显然，访问模块内的内存比访问模块之外的内存要快得多，所以是不一致的，因此在开发程序时尽量减少不同CPU模块之间的信息交互。
- **MPP结构 (Massive Parallel Processing，海量并行处理结构)**
  - 和NUMA不同，MPP由多个SMP服务器作为节点通过一定的互联网络进行连接，协同工作并完成相同的任务，每个服务器节点访问自己的本地资源，是一种完全无共享(Share Nothing)结构，因而扩展能力最好，但需要复制的即使来调度和平衡各个服务器节点的负载和并行处理过程。

那么如何解决？主要有三种方法：

1. **使用show global status**

   以较高频率如一秒执行一次`show global status`命令获取数据，当问题出现时，可以通过某些计数器（比如Threads_rinning，Threads_connected,Questions和Queries）的“尖刺”或“凹陷”老发现。该方法比较简单，所有人都可以使用，不需要特殊权限，对服务器的影响也很小。

2. **使用show processlist**

   该方法是通过不停地捕获`show processlist`的输出，来观察是否由大量线程处于不正常状态或者由其它不正常的特征。

   - 例如查询很少会长时间处于"statistics"状态，这个状态一般是指服务器在查询优化阶段如何确定表关联的顺序——通长都是非常快。
   - 也很少见到大量线程报告当前连接用户是“未经验证的用户”(Unauthenticated user)"，这只是在连接握手的中间过程中的状态，当客户端等待输入用于登录的用户信息的时候会出现。

   使用`show processlist`命令时，在尾部加上\G可以垂直的方式输出结果，这可以使每一行记录的每一列都单独输出为一行，这样可以使用`sort|uniq|sort`一类的命令来计算某个列值出现的次数。

   ```sql
   mysql -e 'SHOW PROCESSLIST\G' | grep State:|sort|uniq -c|sort -rn
   ```

   如果MySQL服务器的版本较新，也可以直接查询`information_schema`的processlist表。

3. **使用查询日志**

   如果要通过查询日志发现问题，需要开启慢查询日志并在全局级别设置long_query_time为0，并且要确认所有的连接都采用了新的设置。这可能需要重置所有的连接以使全局设置剩下；或者使用Percona Server的一个特性。

   - 要注意找到吞吐量突然下降时间段的日志。**查询是在完成阶段才写入到慢查询日志的**，所以堆积会造成大量查询处于查询状态。

### 捕获诊断数据

当间隙性地出现问题时，需要尽可能的收集数据。因为问题是间歇性的，我们应该设置一个触发器来触发数据的收集，而不是一直收集数据直到问题发生，或者等问题发生了才开始收集数据。

- **触发条件**

  选择一个合适的阈值，例如Threads_running的趋势在出现问题时会很敏感，正常则较为稳定。`show processlist`中线程异常状态尖峰也是一个不错的指标。还有包括`show innodb status`的特定输出、服务器的平均负载尖峰等。

  - 当要计算某个状态的数量时，grep的-c选项非常有用：

    `mysql -e 'show processlist\G' | grep -c "State: freeing items"`

  并且当阈值被触发时我们也需要稍微等待一下，避免误报或者短暂的尖峰。

  所有最后的触发条件可以设置为： 每秒监控状态值，比如Threads_running连续5秒超过了20。

- **选择什么工具来监控并收集数据**

  `Percona Toolkit`中的`pt-stalk`就是为这种情况设计的，可以配置需要监控的变量、阈值、检查频率等。

  一些开源的监控工具：Nagios

  命令行监控：innotop

- **收集什么数据呢？**

  **包括系统的状态、CPU利用率、磁盘利用率和可用空间、ps的输出采样、内存利用率，以及可以从MySQL获得的信息，如`show status`，`show processlist`和`show innodb status`等**

当一个未知问题发生时，一般来说有两种可能：

1. 服务器要做大量工作，导致消耗大量的CPU
2. 等待某些资源被释放

而剖析报告用来确认是否有大量工作，等待分析则用来确认是否存在大量等待。

- 在GNU/Linux平台下，可用于服务器内部诊断的一个重要工具是`oprofile`。也可以使用`strace`剖析服务器的系统调用

- 对于等待分析，常用的方法是GDB堆栈分析。MySQL内的线程如果卡在特定的地方很长时间，往往都有相同的堆栈跟踪信息。

  **跟踪过程是先启动gdb，然后attach到mysqld进程，所有线程的堆栈都转储出来。然后可以用一些简短的脚本将类似的堆栈跟踪信息做汇总，利用sort|uniq等排序出总计最多的堆栈信息。**



## MySQL schema设计中的陷阱（废话）

### 太多的列

MySQL的存储引擎API工作时

1. 需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据
2. 然后再服务器层讲缓冲内容解码成各个列

将行缓冲中将解码过的列转换成行数据结构的操作代价非常高，转换的代价依赖于列的数量。



### 太多的关联

所谓的”实体—属性—值“（EAV）设计模式时一个常见的糟糕设计模式。MySQL限制每个关联操作最多只能61张表



## 范式

目前[关系数据库](https://baike.baidu.com/item/关系数据库)有六种范式：[第一范式](https://baike.baidu.com/item/第一范式)（1NF）、[第二范式](https://baike.baidu.com/item/第二范式)（2NF）、[第三范式](https://baike.baidu.com/item/第三范式)（3NF）、Boyce-Codd范式（[BCNF](https://baike.baidu.com/item/BCNF)）、[第四范式](https://baike.baidu.com/item/第四范式)（4NF）和[第五范式](https://baike.baidu.com/item/第五范式)（5NF）。

满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式（3NF）就行了。

- 在创建一个数据库的过程中，范化是将其转化为一些表的过程，这种方法可以使从数据库得到的结果更加明确。这样可能使数据库产生重复数据，从而导致创建多余的表。范化是在识别数据库中的数据元素、关系以及定义所需的表和各表中的项目等这些初始工作之后的一个细化的过程。



- **第一范式（1NF）：数据库表的每一列都是不可分割的基本数据项**

  但是仅仅符合1NF的设计，仍然会存在**数据冗余过大，插入异常，删除异常，修改异常**的问题

- **第二范式（2NF）：在1NF的基础之上，消除了非主属性对于码的部分函数依赖**

  - 函数依赖：可以理解位为在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说**Y函数依赖于X**，**写作 X → Y**。也就是说，在数据表中，不存在任意两条记录，它们在X属性（或属性组）上的值相同，而在Y属性上的值不同。

    - 例：学号作为属性是唯一的，总能对应一个姓名，因此学号 → 姓名；但是反过来可能有同名同姓的人，但是它们的对应的学号并不相同，因此不能说学号依赖于姓名。
    - **完全函数依赖**：在一张表中，若 X → Y，且对于 X 的任何一个真子集X'（假如属性组 X 包含超过一个属性的话），X ' → Y 不成立。也就是说，属性或属性组能够确定一个值，而单单属性组中的某些属性不能确定一个值时，为完全函数依赖。
    - **部分函数依赖**：假如 Y 函数依赖于 X，但同时 Y 并不完全函数依赖于 X，那么我们就称 Y 部分函数依赖于 X，也就是属性组中的某个属性就能确定一个值。
    - **传递函数依赖**：在Y 不包含于 X，且 X 不函数依赖于 Y的前提下， Z 函数依赖于 Y，且 Y 函数依赖于 X，那么我们就称 Z 传递函数依赖于 X 。
    - **码**：设 K 为某表中的一个属性或属性组，若除 K 之外的所有属性（将其看成整体，而不是一个一个判断）都**完全函数依赖于** K（这个“完全”不要漏了），那么我们称 K 为**候选码**，简称为**码**。一张表中可以有超过一个码，通常选择其中一个作为主码。
    - **主属性**：包含在任何一个码中的属性成为主属性。
    - **非主属性**：不在码中的属性值都为非主属性。

  - **如何找出非主属性对于码的部分函数依赖**

    1. **找出数据表中所有的码**

       - 查看每一个单一属性，判断该属性确定了，剩下的所有属性值是否都能确定。比如”姓名“确定了，分数能不能确定，分数和科目也有关，所以不是码。

       - 查看所有包含所有两个属性的属性组...

       - ...

         （查找过程中，属性组里包含已找出的码必定是部分函数依赖，可以忽略）

    2. **根据码找出所有主属性**

    3. **除主属性之外的就是非主属性**

    4. **判断非主属性对于码的部分函数依赖**

       可以理解为非属性对码的部分是否存在函数依赖。

  - **如何消除？**

    通过模式分解，模式分解并不唯一，将出现部分函数依赖的，码的部分和非主属性提取出来并单独形成表。

    - 例：

      对于**（学号，课名） → 姓名**，有 **学号 → 姓名**，存在非主属性 **姓名** 对码**（学号，课名）**的部分函数依赖。
      对于**（学号，课名） → 系名**，有 **学号 → 系名**，存在非主属性 **系名** 对码**（学号，课名）**的部分函数依赖。
      对于**（学号，课名） → 系主任**，有 **学号 → 系主任**，存在非主属性  对码**（学号，课名）**的部分函数依赖。

  - 仍然存在非主属性**系主任**对于码**学号**的**传递函数依赖**，学号 → 系名 → 系主任。导致删除异常和插入异常仍然存在，也数据冗余虽然减少但仍存在。

    - 例：

      删除某个系的所有学生记录，该系的信息消失

      无法插入一个尚无学生的新系的信息。

- **第三范式（3NF）**：**在2NF的基础之上，消除了非主属性对于码的传递函数依赖。**

  - 如何消除？

    我们将存储在传递函数依赖的非主属性提取出来建表

  - 符合3NF要求的数据库设计，**基本**上解决了数据冗余过大，插入异常，修改异常，删除异常的**问题**。

- **BCNF范式**：在 3NF 的基础上消除**主属性**对于码的部分与传递函数依赖

  - 仓库（仓库名，管理员，物品名，数量） 属于哪一级范式？

    答：已知函数依赖集：仓库名 → 管理员，管理员 → 仓库名，（仓库名，物品名）→ 数量
    码：（管理员，物品名），（仓库名，物品名）
    主属性：仓库名、管理员、物品名
    非主属性：数量
    ∵ 不存在非主属性对码的部分函数依赖和传递函数依赖。∴ 此关系模式属于3NF。

  - 虽然处于第三范式，但是

    - 先新增加一个仓库，但尚未存放任何物品，是否可以为该仓库指派管理员？——不可以，因为物品名也是主属性，根据实体完整性的要求，主属性不能为空。

    - 某仓库被清空后，需要删除所有与这个仓库相关的物品存放记录，会带来什么问题？——仓库本身与管理员的信息也被随之删除了。

    - 如果某仓库更换了管理员，会带来什么问题？——这个仓库有几条物品存放记录，就要修改多少次管理员信息。

      即使关系模式符合 3NF 的要求，仍然存在着插入异常，修改异常与删除异常的问题，仍然不是 ”好“ 的设计。存在着**主属性**对于码的部分函数依赖与传递函数依赖。存在主属性【仓库名】对于码【（管理员，物品名）】的部分函数依赖。

      某个码中的主属性与另外一个码存在部分函数依赖

  - 如何消除？

    如上例，讲仓库名和管理员单独建表

    仓库（仓库名，管理员）
    库存（仓库名，物品名，数量）

    

    

    

#### 范式的优缺点

- 范式的优点：更新操作快，因为少了很多冗余数据，不用一个一个地更改，内存占用也减少
- 范式的缺点：查询时可能需要较多的关联，数据都在一张表中可以很好地避免关联，如果不需要要关联表。当数据比内存大时可能要比关联快的多，因为这样避免了随机IO（全表扫描通常时顺序IO）

#### 混用范式化和反范式化

对于已经范式化的表，并且在需要先连接再判断，并且条件满足的情况比较少，如会员查看该会员的访客记录，只有会员才能访问，若将该用户的所有访客进行连接再判断是否是会员比价浪费时间，通常可在混用反范式化，再访客信息记录表中添加该用户会员身份的列。

```sql
#范式化的查询
select message_text,user_name  from message 
inner join user on message.user_id = user.id 
where account_type = 'premium'
order by publish_time desc
limit 10;

#混用的查询
select message_text,user_name from message
where account_type = 'premium' 
order by publish_time desc
limit 10;
```

- **最常见的反范式化数据的方法是复制或缓存**，在不同的表中存储相同的特定列。可以使用触发器更新这些缓存值，使得实现这样的方案变得简单。但需要考虑更新的频率以及更新的时长，并和执行了SELECT查询的频率进行比较。

  缓存一些数据也是为了排序的需要



## 加快Alter table的速度

MySQL的Alter table操作的性能对大表来说是个大问题。其执行的大部分修改表结构操作的方法是用新的结构创建一个空表，从旧表查出所有数据插入新表，然年后再删除旧表。新版本提供一下类型的“在线”操作的支持，这些功能不需要在整个操作过程中锁表。

一般而言，大部分alter table操作将导致MySQL服务中断，对常见的场景，能使用的技巧只有两种：

1. 先在一台不提供服务的机器上执行alter table操作，然后和提供的主库进行切换
2. “影子拷贝”，用要求的表结构创建一张和源表无关的新表，然后通过重命名和删表操作交换两张表。

- 不是所有的alter table操作都会引起表重建，对于某些修改可以只修改.frm文件
  - 创建一张有相同结构的空表，并进行所需要的修改
  - 执行`flush tables with read lock`。这将关闭所有正在使用的表，并且禁止任何表打开
  - 交换.frm文件
  - 执行`unlock tables`释放读锁

## 创建高性能索引

索引是存储引擎用于快速找到记录的一种数据结构。是存储在引擎层而不是服务层实现的，因此不同存储引擎的索引工作方式不同。

### B-Tree索引

通常使用B-Tree实现，意味着所有的值都是按顺序存储的，并且每个叶子到根的距离相同。

![image-20210614093954400](E:\cpp\note\note_picture\image-20210614093954400.png)

从索引的根节点但开始检索，而不需要进行全表扫描。根节点中存放指向子节点的指针，而叶子节点存储指向被索引数据的指针。

B-Tree索引适用于全键值、键值范围或键前缀查找，其中键前缀查找只适用于根据最左前缀的查找。

- B-Tree索引的限制：
  1. 如果不是按照索引的最左列开始查找，则索引失效
  2. 不能跳过索引的中的列
  3. 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找，Like是范围条件

### 哈希索引

哈希索引(hash table)基于哈希表实现，只有精确匹配索引所有列的查询才有效。对于每一行数据都会计算一个哈希码，哈希码是一个较小的值，并且不同键值的行计算出来的哈希码也不一样。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。

目前只有Memory引擎显式支持哈希索引，同时也支持B-Tree索引

- 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。不过，访问内存中行的速度很快，所以大部分情况这一点读性能的影响并不明显。
- 哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序
- 哈希索引也不支持部分索引列匹配查找，因为哈希索引始终是使用索引列的全部内容来计算哈希值的。
- 哈希索引只支持等值比较查询，不支持任何范围查询
- 访问哈希所以的数据非常快，除非有很多哈希冲突，出现哈希索引冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，知道找到所有符合条件的行
- 哈希冲突越多，一些索引维护操作的代价也会很高。例如，如果在某个重复值很多的列上建立哈希索引，那么当从表中删除一行时，存储引擎需要遍历对应哈希子链表中的每一行，找到并删除对应行的引用，冲突越多，代价越大。

InnoDB引擎有一个特殊的功能叫做“自适应哈希索引”（adaptive hash index）。当InnoDB注意到某些索引值被使用得非常频繁时，会在在内存中基于B-Tree索引之上再创建一个哈希索引。这是一个完全自动的、内部的行为，用户无法控制或配置，不过如果有需要可以完全关闭该功能。



### 高性能的索引策略

#### 独立的列

“独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数

如：`select actor_id from sakila,actor where actor_id +1 = 5;`

#### 前缀索引和索引选择性

对于BLOB , TEXT或很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整长度，会使索引变得大且慢。

- 主要在于选择足够长的前缀以保证较高的选择性（不重复占重量的比例），需要观察数据

  `select count(*), left( col , 4)  prex from table1 group by prex;`

#### 多列索引

为where条件里面的列都创建索引，不仅仅为每一列单独创建一个索引，这可能使explain中的extra出现union，通常说明表上的索引建的比较糟糕，这时应该判断索引能否合并，而不是单独的索引。

#### 选择合适的索引列顺序

正确的顺序依赖于使用索引的查询，并同时需要考虑如何更好地满足排序和分组的需要。

在不考虑排序和分组时，将选择性最高的列放到索引最前列

#### 聚簇索引

聚簇索引不是一种索引类型，而是一种数据存储方式。InnoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和数据行。

当表有聚簇索引时，它的数据行实际上存放在索引的叶子节点中。“聚簇”表示数据行和相邻的键值紧凑地存储在一起，因为数据仅存储在一个地方，所以聚簇索引是唯一的。

而非聚簇索引，其叶子节点中存储的是指向数据的指针，也称二级索引。

《数据库原理》描述**聚簇索引的顺序就是数据的物理存储顺序，而对非聚簇索引的解释是:索引顺序与数据物理排列顺序无关。**

## 阿萨







